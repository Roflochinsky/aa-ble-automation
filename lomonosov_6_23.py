# üöÄ –¢–ê–ô–ú–õ–ê–ô–ù–´ AA_BLE (–æ–∫–Ω–æ 6:00‚Äì23:00, –ü–û–ú–ò–ù–£–¢–ù–û)
# - –î–∏–∞–≥—Ä–∞–º–º–∞ –ø–æ –º–µ—Ç–∫–∞–º (–∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ = 1 –º–∏–Ω)
# - –¶–≤–µ—Ç –º–µ—Ç–∫–∏ = –æ—Ç—Ç–µ–Ω–æ–∫ –ø–æ –∑–æ–Ω–µ:
#   1 –∑–µ–ª—ë–Ω—ã–µ, 2 –æ—Ä–∞–Ω–∂–µ–≤—ã–µ, 4 –∫—Ä–∞—Å–Ω—ã–µ, 5 —Ñ–∏–æ–ª–µ—Ç–æ–≤—ã–µ, 7 –∂—ë–ª—Ç—ã–µ, 10 —Å–∏–Ω–∏–µ, 0 —Å–µ—Ä—ã–µ, –ø—Ä–æ—á–µ–µ ‚Äî —Å–µ—Ä—ã–µ
# - –°–ø—Ä–∞–≤–∞ –æ—Ç–¥–µ–ª—å–Ω–∞—è ¬´–∫–∞—Ä—Ç–æ—á–∫–∞¬ª —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º –ø–æ –ó–û–ù–ê–ú –∑–∞ –æ–∫–Ω–æ 6‚Äì23
print("üîÑ –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ aa_ble (6:00‚Äì23:00, –ø–æ–º–∏–Ω—É—Ç–Ω–æ, –ø–∞–Ω–µ–ª—å –≤—Ä–µ–º–µ–Ω–∏ –ø–æ –∑–æ–Ω–∞–º)‚Ä¶")

# –î–ª—è Google Colab
!pip install -q pandas plotly openpyxl odfpy

import io, re, warnings
from datetime import datetime, timedelta, time as dtime
import pandas as pd
import plotly.graph_objects as go
from google.colab import files
warnings.filterwarnings('ignore')

REEXPORT_CODE = "2025"
LAST_EXPORTS = []

def set_reexport_code(new_code):
    global REEXPORT_CODE
    REEXPORT_CODE = str(new_code)
    print("üîê –ö–æ–¥ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –≤—ã–≥—Ä—É–∑–∫–∏ –æ–±–Ω–æ–≤–ª—ë–Ω.")

def list_saved_charts():
    if not LAST_EXPORTS:
        print("‚ö†Ô∏è –ö—ç—à –ø—É—Å—Ç."); return
    print(f"üì¶ –í –∫—ç—à–µ {len(LAST_EXPORTS)} –¥–∏–∞–≥—Ä–∞–º–º:")
    for i, it in enumerate(LAST_EXPORTS, 1):
        print(f"  {i}) –¥–∞—Ç–∞={it['date_str']}, —Ä–∞–∑–¥–µ–ª={it['area_suffix']}, —Å–æ—Ç—Ä—É–¥–Ω–∏–∫={it.get('employee','')}")

def clear_saved_charts():
    LAST_EXPORTS.clear()
    print("üßπ –ö—ç—à –¥–∏–∞–≥—Ä–∞–º–º –æ—á–∏—â–µ–Ω.")

def redownload_last_charts(code=None):
    if code is None:
        code = input("–í–≤–µ–¥–∏—Ç–µ –∫–æ–¥ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –≤—ã–≥—Ä—É–∑–∫–∏: ").strip()
    if str(code) != str(REEXPORT_CODE):
        print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –∫–æ–¥."); return
    if not LAST_EXPORTS:
        print("‚ö†Ô∏è –ù–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –¥–∏–∞–≥—Ä–∞–º–º."); return
    print("‚ôªÔ∏è –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –≤—ã–≥—Ä—É–∑–∫–∞ –¥–∏–∞–≥—Ä–∞–º–º...")
    for it in LAST_EXPORTS:
        export_chart_auto(it['fig'], it['date_str'], area_suffix=it['area_suffix'], employee=it.get('employee'))
    print("‚úÖ –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –≤—ã–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

def round_051(x):
    if pd.isna(x): return x
    try: val = float(x)
    except: return x
    frac = abs(val) - abs(int(val))
    up = abs(int(val)) + 1; dn = abs(int(val))
    res = up if frac >= 0.51 else dn
    return res if val >= 0 else -res

def parse_date(s):
    if pd.isna(s): return None
    # –ï—Å–ª–∏ pandas —É–∂–µ –ø—Ä–æ—á–∏—Ç–∞–ª –∫–∞–∫ datetime ‚Äî —Å—Ä–∞–∑—É –≤–æ–∑–≤—Ä–∞—â–∞–µ–º .date()
    if isinstance(s, (pd.Timestamp, datetime)):
        return s.date()
    # –ò–Ω–∞—á–µ –ø–∞—Ä—Å–∏–º: —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º yearfirst –¥–ª—è ISO (2025-10-01), –ø–æ—Ç–æ–º dayfirst
    d = pd.to_datetime(s, yearfirst=True, errors='coerce')
    if pd.isna(d):
        d = pd.to_datetime(s, dayfirst=True, errors='coerce')
    return d.date() if pd.notna(d) else None

def parse_time_only(val):
    if pd.isna(val): return None
    s = str(val).strip()
    for fmt in ('%H:%M:%S','%H:%M'):
        try: return datetime.strptime(s, fmt).time()
        except: pass
    try:
        v = float(s); base = datetime(1899,12,30)
        return (base + timedelta(days=v)).time()
    except: return None

def parse_date_from_filename(filename: str):
    name = str(filename)
    m = re.search(r'(\d{4})[ _.-](\d{2})[ _.-](\d{2})', name)
    if m:
        try: return datetime(int(m[1]), int(m[2]), int(m[3])).date()
        except: pass
    m = re.search(r'(\d{2})[ _.-](\d{2})[ _.-](\d{4})', name)
    if m:
        try: return datetime(int(m[3]), int(m[2]), int(m[1])).date()
        except: pass
    return None

def infer_file_date_from_df(df):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –¥–∞—Ç—É –æ—Ç—á—ë—Ç–∞ –ø–æ –ü–ï–†–í–û–ú–£ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–º—É –∑–Ω–∞—á–µ–Ω–∏—é –¥–∞—Ç—ã/–≤—Ä–µ–º–µ–Ω–∏ –≤ —Ñ–∞–π–ª–µ.
    –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∫–æ–ª–æ–Ω–æ–∫: 'date'/'–¥–∞—Ç–∞' ‚Üí '–¥–∞—Ç–∞ –Ω–∞ –æ–±—ä–µ–∫—Ç–µ' ‚Üí 'shift day'/'shift_day'/'–¥–µ–Ω—å —Å–º–µ–Ω—ã' ‚Üí –ª—é–±–æ–π datetime-–ø–æ–¥–æ–±–Ω—ã–π –∏–∑ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç date –∏–ª–∏ None."""
    try:
        cols = [str(c).strip() for c in df.columns]
        low = {i: str(c).strip().lower() for i, c in enumerate(cols)}
        def find_col(candidates):
            for i, name in low.items():
                for cand in candidates:
                    if name == cand or cand in name:
                        return i
            return None
        # 1) –ò—â–µ–º —è–≤–Ω—É—é –∫–æ–ª–æ–Ω–∫—É –¥–∞—Ç—ã (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: date/–¥–∞—Ç–∞, –∑–∞—Ç–µ–º –¥–∞—Ç–∞ –Ω–∞ –æ–±—ä–µ–∫—Ç–µ, –∑–∞—Ç–µ–º –¥–µ–Ω—å —Å–º–µ–Ω—ã)
        ix_date = find_col(['date','–¥–∞—Ç–∞'])
        ix_date_obj = find_col(['–¥–∞—Ç–∞ –Ω–∞ –æ–±—ä–µ–∫—Ç–µ','date on site'])
        ix_shift = find_col(['shift day','shift_day','–¥–µ–Ω—å —Å–º–µ–Ω—ã','–¥–µ–Ω—å'])

        print(f"üîç –ü–æ–∏—Å–∫ –¥–∞—Ç—ã: ix_date={ix_date}, ix_date_obj={ix_date_obj}, ix_shift={ix_shift}")

        for ix in [ix_date, ix_date_obj, ix_shift]:
            if ix is not None and ix < df.shape[1]:
                print(f"üîç –ü—Ä–æ–±—É–µ–º –∫–æ–ª–æ–Ω–∫—É {ix} ({cols[ix]}), –ø–µ—Ä–≤—ã–µ 3 –∑–Ω–∞—á–µ–Ω–∏—è: {df.iloc[:3, ix].tolist()}")
                s = pd.to_datetime(df.iloc[:, ix], errors='coerce')
                val = s.dropna().iloc[0] if not s.dropna().empty else None
                if pd.notna(val):
                    print(f"‚úÖ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –¥–∞—Ç–∞ —Ñ–∞–π–ª–∞ –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ '{cols[ix]}': {val.date()}")
                    return val.date()
        # 2) –ü—Ä–æ–±—É–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É: –±–µ—Ä—ë–º –ø–µ—Ä–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, –ø–æ—Ö–æ–∂–µ–µ –Ω–∞ –¥–∞—Ç—É/–≤—Ä–µ–º—è
        print("üîç –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –¥–∞—Ç—É –≤ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–µ –¥–∞–Ω–Ω—ã—Ö...")
        if df.shape[0] > 0:
            first_row = df.iloc[0, :]
            for i, v in enumerate(first_row.values):
                dt = pd.to_datetime(v, errors='coerce')
                if pd.notna(dt):
                    print(f"‚úÖ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –¥–∞—Ç–∞ —Ñ–∞–π–ª–∞ –∏–∑ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏, –∫–æ–ª–æ–Ω–∫–∞ {i} ({cols[i] if i < len(cols) else '–±–µ–∑ –∏–º–µ–Ω–∏'}): {dt.date()}")
                    return dt.date()
        print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–∞—Ç—É —Ñ–∞–π–ª–∞ –∏–∑ –¥–∞–Ω–Ω—ã—Ö")
        return None
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –¥–∞—Ç—ã —Ñ–∞–π–ª–∞: {e}")
        return None

def format_file_date_for_title(d):
    if not d: return ""
    return datetime.strftime(pd.to_datetime(d), "%d-%m-%Y")

def load_aable_second_sheet_multi(date_from=None, date_to=None):
    print("üìà –ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤ aa_ble (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 2-–π –ª–∏—Å—Ç):")
    uploaded = files.upload()
    if not uploaded: return None
    frames = []
    for filename, raw in uploaded.items():
        try:
            if filename.endswith(('.xlsx','.xls')):
                xls = pd.ExcelFile(io.BytesIO(raw))
                sheet = xls.sheet_names[1] if len(xls.sheet_names) >= 2 else xls.sheet_names[0]
                df = xls.parse(sheet)
            elif filename.endswith('.csv'):
                df = pd.read_csv(io.StringIO(raw.decode('utf-8')))
            else:
                print(f"‚ùå –ü—Ä–æ–ø—É—â–µ–Ω '{filename}' ‚Äî –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç"); continue
            df['__source__'] = filename
            inferred = infer_file_date_from_df(df)
            file_date = inferred or parse_date_from_filename(filename)
            df['__file_date__'] = file_date
            frames.append(df)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ '{filename}': {e}")
    if not frames: return None
    all_df_raw = pd.concat(frames, ignore_index=True)
    print("üîé –ò—Å—Ö–æ–¥–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏:", list(all_df_raw.columns))
    all_df = normalize_aable_columns(all_df_raw)
    all_df['shift_day'] = all_df['shift_day'].apply(parse_date)
    all_df['time_only'] = all_df['time_only'].apply(parse_time_only)

    # –û–¢–õ–ê–î–ö–ê: –ø–æ–∫–∞–∑—ã–≤–∞–µ–º, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ø–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞
    print(f"üîç –ü–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞: –∑–∞–ø–∏—Å–µ–π={len(all_df)}")
    print(f"üîç shift_day (—É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è): {all_df['shift_day'].dropna().unique()}")
    if '__file_date__' in all_df.columns:
        print(f"üîç __file_date__ (–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è –¥–∞—Ç–∞ —Ñ–∞–π–ª–∞): {all_df['__file_date__'].dropna().unique()}")

    if date_from or date_to:
        dfrom = pd.to_datetime(date_from, dayfirst=True, errors='coerce').date() if date_from else None
        dto = pd.to_datetime(date_to, dayfirst=True, errors='coerce').date() if date_to else None
        mask = pd.Series(True, index=all_df.index)
        if dfrom: mask &= (all_df['shift_day'] >= dfrom)
        if dto:   mask &= (all_df['shift_day'] <= dto)
        all_df = all_df[mask]
        print(f"üîç –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ –ø–µ—Ä–∏–æ–¥—É: –∑–∞–ø–∏—Å–µ–π={len(all_df)}")

    # –í–ê–ñ–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –∑–∞–ø–∏—Å–∏ —Ç–æ–≥–æ –¥–Ω—è, –∫–æ—Ç–æ—Ä—ã–π –æ–ø—Ä–µ–¥–µ–ª—ë–Ω –∫–∞–∫ –¥–∞—Ç–∞ —Ñ–∞–π–ª–∞ (–ø–µ—Ä–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –¥–∞—Ç–∞)
    if '__file_date__' in all_df.columns:
        fd_series = pd.to_datetime(all_df['__file_date__'], errors='coerce').dt.date
        print(f"üîç –§–∏–ª—å—Ç—Ä—É–µ–º: –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –∑–∞–ø–∏—Å–∏ –≥–¥–µ shift_day == {fd_series.unique() if hasattr(fd_series, 'unique') else fd_series}")
        all_df = all_df[all_df['shift_day'] == fd_series]
        print(f"üîç –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ –¥–∞—Ç–µ —Ñ–∞–π–ª–∞: –∑–∞–ø–∏—Å–µ–π={len(all_df)}")

    print(f"‚úÖ aa_ble: –∑–∞–ø–∏—Å–µ–π={len(all_df)}")
    print(all_df.head(3))
    return all_df

def load_ble_journal():
    print("üìñ –ó–∞–≥—Ä—É–∑–∏—Ç–µ '–ñ—É—Ä–Ω–∞–ª BLE' (–º–µ—Ç–∫–∞ ‚Üí –æ–ø–∏—Å–∞–Ω–∏–µ/–ª–æ–∫–∞—Ü–∏—è):")
    uploaded = files.upload()
    if not uploaded: return None
    filename = list(uploaded.keys())[0]
    try:
        if filename.endswith(('.xlsx','.xls')):
            df = pd.read_excel(io.BytesIO(uploaded[filename]))
        elif filename.endswith('.csv'):
            df = pd.read_csv(io.StringIO(uploaded[filename].decode('utf-8')))
        else:
            print("‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –∂—É—Ä–Ω–∞–ª–∞ BLE"); return None
        print(f"‚úÖ –ñ—É—Ä–Ω–∞–ª BLE –∑–∞–≥—Ä—É–∂–µ–Ω: {len(df)} –∑–∞–ø–∏—Å–µ–π")
        return df
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∂—É—Ä–Ω–∞–ª–∞ BLE: {e}")
        return None

def load_people_mapping():
    print("üóÇ –ó–∞–≥—Ä—É–∑–∏—Ç–µ '–ü—Ä–∏–≤—è–∑–∫–∞ –ª—é–¥–µ–π' (A: –¢–ù, B: –§–ò–û, D: –£—á–∞—Å—Ç–æ–∫ –†–∞–±–æ—Ç):")
    uploaded = files.upload()
    if not uploaded: return None
    filename = list(uploaded.keys())[0]
    try:
        if filename.endswith(('.xlsx','.xls')):
            df = pd.read_excel(io.BytesIO(uploaded[filename]))
        elif filename.endswith('.csv'):
            df = pd.read_csv(io.StringIO(uploaded[filename].decode('utf-8')))
        else:
            print("‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –ø—Ä–∏–≤—è–∑–∫–∏"); return None
        print(f"‚úÖ –ü—Ä–∏–≤—è–∑–∫–∞ –ª—é–¥–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {len(df)} –∑–∞–ø–∏—Å–µ–π")
        return df
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –ø—Ä–∏–≤—è–∑–∫–∏: {e}")
        return None

def build_area_map(mapping_df):
    area_map = {}
    if mapping_df is None or mapping_df.empty: return area_map
    for _, row in mapping_df.iterrows():
        try:
            tn = str(row.iloc[0]).strip()
            area = str(row.iloc[3]).strip() if len(row) > 3 else ""
            if tn and area and area.lower() != 'nan':
                area_map[tn] = area
        except: continue
    print(f"‚úÖ –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∞ –∫–∞—Ä—Ç–∞ —É—á–∞—Å—Ç–∫–æ–≤: {len(area_map)} —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤")
    return area_map

def build_fio_map(mapping_df):
    """–°–æ–∑–¥–∞–µ—Ç –∫–∞—Ä—Ç—É –¢–ù -> –§–ò–û –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ B —Ñ–∞–π–ª–∞ '–ü—Ä–∏–≤—è–∑–∫–∞ –ª—é–¥–µ–π'"""
    fio_map = {}
    if mapping_df is None or mapping_df.empty: return fio_map
    for _, row in mapping_df.iterrows():
        try:
            tn = str(row.iloc[0]).strip()
            fio = str(row.iloc[1]).strip() if len(row) > 1 else ""  # –ö–æ–ª–æ–Ω–∫–∞ B (–∏–Ω–¥–µ–∫—Å 1)
            if tn and fio and fio.lower() != 'nan':
                fio_map[tn] = fio
        except: continue
    print(f"‚úÖ –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∞ –∫–∞—Ä—Ç–∞ –§–ò–û: {len(fio_map)} —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤")
    return fio_map

def normalize_aable_columns(df):
    orig = df.copy()
    cols = list(orig.columns)
    low = {i: str(c).strip().lower() for i, c in enumerate(cols)}
    def find_by_name(needles):
        for i, name in low.items():
            for n in needles:
                if name == n: return i
        for i, name in low.items():
            for n in needles:
                if n in name: return i
        return None
    POS = {'tn_number':0,'shift_day':3,'ble_tag':10,'zone_id':11,'time_only':15}
    IX_TN   = find_by_name(['—Ç–Ω','tn','—Ç–∞–±','—Ç–∞–±–µ–ª—å','tabnum','tab_num','personal'])
    IX_DAY  = find_by_name(['–¥–µ–Ω—å —Å–º–µ–Ω—ã','shift day','shift_day','–¥–µ–Ω—å','—Å–º–µ–Ω—ã'])
    IX_TAG  = find_by_name(['ble','–º–µ—Ç–∫','mekta','metka','–º–∞—è—á','tag'])
    IX_ZONE = find_by_name(['zona','–∑–æ–Ω–∞','zone'])
    IX_TIME = find_by_name(['–≤—Ä–µ–º—è –Ω–∞ –æ–±—ä–µ–∫—Ç–µ','–≤—Ä–µ–º—è','time'])
    def pick(ix_name, pos_key):
        ix = {'tn_number':IX_TN,'shift_day':IX_DAY,'ble_tag':IX_TAG,'zone_id':IX_ZONE,'time_only':IX_TIME}[ix_name]
        if ix is not None and ix < orig.shape[1]: return orig.iloc[:, ix]
        pos = POS[pos_key]
        return orig.iloc[:, pos] if pos < orig.shape[1] else pd.Series([None]*len(orig))
    out = pd.DataFrame({
        'tn_number': pick('tn_number','tn_number'),
        'shift_day': pick('shift_day','shift_day'),
        'ble_tag': pick('ble_tag','ble_tag'),
        'zone_id': pick('zone_id','zone_id'),
        'time_only': pick('time_only','time_only'),
    })
    if '__source__' in orig.columns: out['__source__'] = orig['__source__']
    if '__file_date__' in orig.columns: out['__file_date__'] = orig['__file_date__']
    def src_name(s):
        try: return cols[s] if s is not None and s < len(cols) else None
        except: return None
    print("üß≠ –ú–∞–ø–ø–∏–Ω–≥ –∫–æ–ª–æ–Ω–æ–∫:",
          f"\n  tn_number ‚Üê {src_name(IX_TN) or 'A'}",
          f"\n  shift_day ‚Üê {src_name(IX_DAY) or 'D'}",
          f"\n  ble_tag   ‚Üê {src_name(IX_TAG) or 'K'}",
          f"\n  zone_id   ‚Üê {src_name(IX_ZONE) or 'L'}",
          f"\n  time_only ‚Üê {src_name(IX_TIME) or 'P'}")
    return out

def attach_ble_desc_map(ble_journal_df):
    if ble_journal_df is None or ble_journal_df.empty: return {}
    jr = ble_journal_df.copy()
    jr.iloc[:,0] = jr.iloc[:,0].astype(str).str.strip()
    if jr.shape[1] < 4: return {}
    jr['__desc__'] = jr.iloc[:,3].astype(str).str.strip()
    d = {}
    for _, r in jr.iterrows():
        key = r.iloc[0]; val = r['__desc__']
        if str(val).strip(): d[str(key)] = val
    return d

PALETTES = {
    1: ['#27AE60','#2ECC71','#229954','#1E8449','#58D68D'],  # –ó–æ–Ω—ã –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è —Ä–∞–±–æ—Ç - –∑–µ–ª–µ–Ω—ã–π
    4: ['#E74C3C','#C0392B','#E53935','#D32F2F','#FF6F61'],  # –ö—É—Ä–∏–ª–∫–∏ - –∫—Ä–∞—Å–Ω—ã–π
    10:['#1F77B4','#2980B9','#3498DB','#2874A6','#5DADE2'],  # –ó–æ–Ω–∞ –≤—ã–¥–∞—á–∏ WW - —Å–∏–Ω–∏–π
    13:['#E67E22','#F39C12','#D35400','#E67E22','#F1C40F'],  # –ö–ü–ü - –æ—Ä–∞–Ω–∂–µ–≤—ã–π
    2: ['#E67E22','#F39C12','#D35400','#E67E22','#F1C40F'],
    5: ['#8E44AD','#9B59B6','#7D3C98','#6C3483','#AF7AC5'],
    7: ['#F1C40F','#F4D03F','#F7DC6F','#D4AC0D','#F9E79F'],
    0: ['#95A5A6','#7F8C8D','#B0B0B0','#A0A0A0','#BDC3C7'],
    'other': ['#95A5A6','#7F8C8D','#B0B0B0','#A0A0A0','#BDC3C7']
}
def color_for_tag_zone(tag, zone_id):
    try: zid = int(zone_id) if pd.notna(zone_id) else 0
    except: zid = 0
    pal = PALETTES.get(zid, PALETTES['other'])
    try: idx = abs(int(float(tag))) % len(pal)
    except: idx = 0
    return pal[idx]

# ROW‚ÜíMINUTE: –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ = 1 –º–∏–Ω—É—Ç–∞ –¥–ª—è –º–µ—Ç–∫–∏
def build_user_minute_bins_by_tag(df_user):
    rows = df_user.dropna(subset=['shift_day','time_only']).sort_values(['shift_day','time_only']).to_dict('records')
    if not rows: return []
    minute_bins = []; prev_dt = None; current_day = rows[0]['shift_day']
    for r in rows:
        day = r['shift_day'] or current_day
        t = r['time_only']
        if t is None: continue
        dt = datetime.combine(day, t)
        if prev_dt and dt < prev_dt:
            dt = datetime.combine(day + timedelta(days=1), t)
            current_day = day + timedelta(days=1)
        else:
            current_day = day
        try: tag_val = int(float(str(r.get('ble_tag')))) if r.get('ble_tag') not in [None,""] else 0
        except: tag_val = 0
        try: zone_val = int(r.get('zone_id')) if pd.notna(r.get('zone_id')) else 0
        except: zone_val = 0
        minute_bins.append({'start': dt, 'end': dt + timedelta(minutes=1), 'ble_tag': tag_val, 'zone_id': zone_val})
        prev_dt = dt
    return minute_bins

def build_segments_all(df, area_map, fio_map):
    out_rows = []
    for (tn, shift_day), g in df.groupby(['tn_number','shift_day']):
        bins = build_user_minute_bins_by_tag(g)
        file_dates = g['__file_date__'].dropna().astype(str)
        file_date = file_dates.mode().iloc[0] if not file_dates.empty else None
        for b in bins:
            area = area_map.get(str(tn).strip(), '')
            fio = fio_map.get(str(tn).strip(), f"–¢–ù {str(tn).strip()}")  # Fallback –∫ –¢–ù –µ—Å–ª–∏ –§–ò–û –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
            zid = b['zone_id'] if pd.notna(b['zone_id']) else 0
            out_rows.append({
                'tn_number': str(tn).strip(),
                'employee': fio,
                'area': area,
                'date': b['start'].date(),
                'file_date': file_date,
                'start': b['start'],
                'end': b['end'],
                'duration_minutes': 1.0,
                'ble_tag': b['ble_tag'],
                'zone_id': zid,
                'zone_name': {0:"–í–Ω–µ –∑–æ–Ω—ã BLE-–º–∞—è—á–∫–æ–≤",1:"–ó–æ–Ω—ã –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è —Ä–∞–±–æ—Ç",2:"–°—Ç–æ–ª–æ–≤—ã–µ",3:"–û–ø–∞—Å–Ω—ã–µ –∑–æ–Ω—ã",4:"–ö—É—Ä–∏–ª–∫–∏",5:"–ó–æ–Ω—ã –æ—Ç–¥—ã—Ö–∞",6:"–í–ñ–ì",7:"–¢—É–∞–ª–µ—Ç—ã",8:"–û—Å—Ç–∞–Ω–æ–≤–∫–∏ –∞–≤—Ç–æ–±—É—Å–æ–≤",9:"–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–µ –ø–æ–º–µ—â–µ–Ω–∏—è",10:"–ó–æ–Ω–∞ –≤—ã–¥–∞—á–∏ WW",11:"–°–∫–ª–∞–¥",12:"–ú–∞—Å—Ç–µ—Ä—Å–∫–∏–µ",13:"–ö–ü–ü"}.get(zid, f"–ó–æ–Ω–∞ {zid}"),
            })
    out = pd.DataFrame(out_rows)
    if not out.empty:
        out = out.sort_values(['date','employee','start'])
        out['duration_minutes'] = out['duration_minutes'].apply(round_051)
    return out

def report_zero_metka(df_raw):
    s = df_raw.get('ble_tag')
    if s is None:
        print("‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ –º–µ—Ç–∫–∏ BLE –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç."); return
    mask0 = s.isna() | (s.astype(str).str.strip().isin(['0','0.0','']))
    counts = df_raw.loc[mask0].groupby('tn_number').size().sort_values(ascending=False)
    offenders = counts[counts > 100]
    if offenders.empty:
        print("‚úÖ –ù–µ—Ç —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ —Å >100 —Å—Ç—Ä–æ–∫ –º–µ—Ç–∫–∏ 0.")
    else:
        print("‚ùó >100 —Å—Ç—Ä–æ–∫ –º–µ—Ç–∫–∏ 0 (–í–Ω–µ –∑–æ–Ω—ã BLE):")
        print(offenders.to_string())
    return offenders

def log_time_gaps(df_raw, fio_map):
    """–õ–æ–≥–∏—Ä—É–µ—Ç —Ä–∞–∑—Ä—ã–≤—ã –≤–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ (–¢–ù) –ø–æ —Å–º–µ–Ω–∞–º"""
    if df_raw is None or df_raw.empty:
        print("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞–∑—Ä—ã–≤–æ–≤")
        return

    print("\n" + "=" * 70)
    print("üîç –ê–ù–ê–õ–ò–ó –†–ê–ó–†–´–í–û–í –í–û –í–†–ï–ú–ï–ù–ò –ü–û –°–û–¢–†–£–î–ù–ò–ö–ê–ú")
    print("=" * 70)

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –¢–ù –∏ –¥–Ω—é —Å–º–µ–Ω—ã
    gaps_found = False
    for tn, tn_group in df_raw.groupby('tn_number'):
        tn_str = str(tn).strip()
        fio = fio_map.get(tn_str, f"–¢–ù {tn_str}")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–º–µ–Ω–∞–º –¥–ª—è —ç—Ç–æ–≥–æ –¢–ù
        shift_stats = {}
        shift_gaps = {}

        for shift_day, day_group in tn_group.groupby('shift_day'):
            if pd.isna(shift_day):
                continue

            # –ü–æ–ª—É—á–∞–µ–º –≤—Ä–µ–º–µ–Ω–∞ –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
            times = day_group['time_only'].dropna().tolist()
            times_sorted = sorted([t for t in times if t is not None])

            if len(times_sorted) < 2:
                continue

            # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∏–Ω—É—Ç –≤ —Å–º–µ–Ω–µ
            shift_stats[shift_day] = len(times_sorted)

            # –ò—â–µ–º —Ä–∞–∑—Ä—ã–≤—ã
            gaps = []
            for i in range(1, len(times_sorted)):
                prev_time = times_sorted[i-1]
                curr_time = times_sorted[i]

                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –º–∏–Ω—É—Ç—ã –æ—Ç –ø–æ–ª—É–Ω–æ—á–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                prev_mins = prev_time.hour * 60 + prev_time.minute
                curr_mins = curr_time.hour * 60 + curr_time.minute

                diff = curr_mins - prev_mins
                if diff > 1:  # –†–∞–∑—Ä—ã–≤ –±–æ–ª—å—à–µ 1 –º–∏–Ω—É—Ç—ã
                    expected_time = (datetime.combine(datetime.today(), prev_time) + timedelta(minutes=1)).time()
                    gaps.append({
                        'from': prev_time.strftime('%H:%M'),
                        'to': curr_time.strftime('%H:%M'),
                        'expected': expected_time.strftime('%H:%M'),
                        'gap_minutes': diff - 1
                    })

            if gaps:
                shift_gaps[shift_day] = gaps

        # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–∞–∑—Ä—ã–≤—ã –¥–ª—è —ç—Ç–æ–≥–æ –¢–ù ‚Äî –≤—ã–≤–æ–¥–∏–º
        if shift_gaps:
            gaps_found = True
            # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—É—é –±–æ–ª—å—à—É—é —Å–º–µ–Ω—É
            if shift_stats:
                max_shift = max(shift_stats, key=shift_stats.get)
                max_shift_mins = shift_stats[max_shift]
                max_shift_str = max_shift.strftime('%d.%m.%Y') if hasattr(max_shift, 'strftime') else str(max_shift)
            else:
                max_shift_str = "–Ω/–¥"
                max_shift_mins = 0

            print(f"\nüë§ {fio} (–¢–ù: {tn_str})")
            print(f"   üìä –°–∞–º–∞—è –±–æ–ª—å—à–∞—è —Å–º–µ–Ω–∞: {max_shift_str} ({max_shift_mins} –º–∏–Ω)")

            for shift_day, gaps in shift_gaps.items():
                shift_str = shift_day.strftime('%d.%m.%Y') if hasattr(shift_day, 'strftime') else str(shift_day)
                shift_mins = shift_stats.get(shift_day, 0)
                print(f"   üìÖ –°–º–µ–Ω–∞ {shift_str} ({shift_mins} –º–∏–Ω):")
                for gap in gaps:
                    print(f"      ‚ö†Ô∏è –†–∞–∑—Ä—ã–≤: {gap['from']} ‚Üí {gap['to']} (–æ–∂–∏–¥–∞–ª–æ—Å—å {gap['expected']}, –ø—Ä–æ–ø—É—â–µ–Ω–æ {gap['gap_minutes']} –º–∏–Ω)")

    if not gaps_found:
        print("‚úÖ –†–∞–∑—Ä—ã–≤–æ–≤ –≤–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.")

    print("=" * 70 + "\n")

def analyze_tag_zones(df_raw):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–µ—Ç–æ–∫ –ø–æ –∑–æ–Ω–∞–º"""
    if df_raw is None or df_raw.empty:
        print("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∑–æ–Ω –º–µ—Ç–æ–∫")
        return

    print("\nüîç –ê–ù–ê–õ–ò–ó –ú–ï–¢–û–ö –ü–û –ó–û–ù–ê–ú:")
    print("=" * 50)

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –º–µ—Ç–∫–µ –∏ –∑–æ–Ω–µ
    tag_zone_analysis = df_raw.groupby(['ble_tag', 'zone_id']).size().reset_index(name='count')
    tag_zone_analysis = tag_zone_analysis.sort_values(['ble_tag', 'count'], ascending=[True, False])

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-10 –º–µ—Ç–æ–∫ —Å –∏—Ö –∑–æ–Ω–∞–º–∏
    top_tags = tag_zone_analysis['ble_tag'].value_counts().head(10)

    for tag in top_tags.index:
        if pd.notna(tag) and str(tag).strip() not in ['0', '0.0', '']:
            tag_data = tag_zone_analysis[tag_zone_analysis['ble_tag'] == tag]
            print(f"\nüìå –ú–µ—Ç–∫–∞ {tag}:")
            for _, row in tag_data.iterrows():
                zone_id = int(row['zone_id']) if pd.notna(row['zone_id']) else 0
                zone_name = {0:"–í–Ω–µ –∑–æ–Ω—ã BLE-–º–∞—è—á–∫–æ–≤",1:"–ó–æ–Ω—ã –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è —Ä–∞–±–æ—Ç",2:"–°—Ç–æ–ª–æ–≤—ã–µ",3:"–û–ø–∞—Å–Ω—ã–µ –∑–æ–Ω—ã",4:"–ö—É—Ä–∏–ª–∫–∏",5:"–ó–æ–Ω—ã –æ—Ç–¥—ã—Ö–∞",6:"–í–ñ–ì",7:"–¢—É–∞–ª–µ—Ç—ã",8:"–û—Å—Ç–∞–Ω–æ–≤–∫–∏ –∞–≤—Ç–æ–±—É—Å–æ–≤",9:"–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–µ –ø–æ–º–µ—â–µ–Ω–∏—è",10:"–ó–æ–Ω–∞ –≤—ã–¥–∞—á–∏ WW",11:"–°–∫–ª–∞–¥",12:"–ú–∞—Å—Ç–µ—Ä—Å–∫–∏–µ",13:"–ö–ü–ü"}.get(zone_id, f"–ó–æ–Ω–∞ {zone_id}")
                print(f"   –ó–æ–Ω–∞ {zone_id} ({zone_name}): {int(row['count'])} –∑–∞–ø–∏—Å–µ–π")

    # –°–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è –º–µ—Ç–∫–∏ 1
    if 1 in df_raw['ble_tag'].values:
        print(f"\nüéØ –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ú–ï–¢–ö–ò 1:")
        tag1_data = df_raw[df_raw['ble_tag'] == 1]
        if not tag1_data.empty:
            zone_dist = tag1_data['zone_id'].value_counts().sort_index()
            for zone_id, count in zone_dist.items():
                zone_name = {0:"–í–Ω–µ –∑–æ–Ω—ã BLE-–º–∞—è—á–∫–æ–≤",1:"–ó–æ–Ω—ã –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è —Ä–∞–±–æ—Ç",2:"–°—Ç–æ–ª–æ–≤—ã–µ",3:"–û–ø–∞—Å–Ω—ã–µ –∑–æ–Ω—ã",4:"–ö—É—Ä–∏–ª–∫–∏",5:"–ó–æ–Ω—ã –æ—Ç–¥—ã—Ö–∞",6:"–í–ñ–ì",7:"–¢—É–∞–ª–µ—Ç—ã",8:"–û—Å—Ç–∞–Ω–æ–≤–∫–∏ –∞–≤—Ç–æ–±—É—Å–æ–≤",9:"–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–µ –ø–æ–º–µ—â–µ–Ω–∏—è",10:"–ó–æ–Ω–∞ –≤—ã–¥–∞—á–∏ WW",11:"–°–∫–ª–∞–¥",12:"–ú–∞—Å—Ç–µ—Ä—Å–∫–∏–µ",13:"–ö–ü–ü"}.get(zone_id, f"–ó–æ–Ω–∞ {zone_id}")
                print(f"   –ó–æ–Ω–∞ {zone_id} ({zone_name}): {count} –∑–∞–ø–∏—Å–µ–π")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
            if 'time_only' in tag1_data.columns:
                print(f"\n‚è∞ –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–µ—Ç–∫–∏ 1:")
                tag1_data['hour'] = pd.to_datetime(tag1_data['time_only'], errors='coerce').dt.hour
                hourly_zones = tag1_data.groupby(['hour', 'zone_id']).size().reset_index(name='count')
                for hour in sorted(hourly_zones['hour'].dropna().unique()):
                    hour_data = hourly_zones[hourly_zones['hour'] == hour]
                    zones_str = ", ".join([f"–∑–æ–Ω–∞{int(z)}" for z in hour_data['zone_id']])
                    print(f"   {int(hour):02d}:00 - {zones_str}")

    return tag_zone_analysis

def lighten_color(hex_color, factor=0.3):
    """–û—Å–≤–µ—Ç–ª—è–µ—Ç hex —Ü–≤–µ—Ç –Ω–∞ –∑–∞–¥–∞–Ω–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä (0-1)"""
    hex_color = hex_color.lstrip('#')
    r, g, b = int(hex_color[0:2], 16), int(hex_color[2:4], 16), int(hex_color[4:6], 16)
    r = int(r + (255 - r) * factor)
    g = int(g + (255 - g) * factor)
    b = int(b + (255 - b) * factor)
    return f'#{r:02x}{g:02x}{b:02x}'

def create_user_timeline_chart_window(df_user, tag_desc_map, row_height=60, window_start=(6,0), window_end=(23,0)):
    if df_user is None or df_user.empty: return None, None
    df = df_user.copy()
    df['start'] = pd.to_datetime(df['start']); df['end'] = pd.to_datetime(df['end'])
    file_date = df.get('file_date')
    file_date = file_date.iloc[0] if file_date is not None and not file_date.empty else None
    display_date = pd.to_datetime(file_date).date() if file_date else df['start'].dt.date.min()
    ws = datetime.combine(display_date, dtime(window_start[0], window_start[1]))
    we = datetime.combine(display_date, dtime(window_end[0], window_end[1]))
    df = df[(df['start'] >= ws) & (df['start'] < we)].copy()
    if df.empty: return None, None
    df['duration_ms'] = (df['end'] - df['start']).dt.total_seconds() * 1000
    user = df['employee'].iloc[0]
    total_by_tag = df.groupby(['ble_tag','zone_id'])['duration_minutes'].sum().to_dict()
    zone_sum = df.groupby('zone_id')['duration_minutes'].sum().apply(round_051).sort_index()
    
    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –º–µ—Ç–∫–∞–º –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–π –∑–æ–Ω—ã
    zone_tags_data = {}
    for (tag, zid), minutes in total_by_tag.items():
        if zid not in zone_tags_data:
            zone_tags_data[zid] = []
        tag_int = int(tag) if pd.notna(tag) else 0
        mins = int(round_051(minutes))
        zone_tags_data[zid].append({'tag': tag_int, 'minutes': mins})
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –º–µ—Ç–∫–∏ –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–π –∑–æ–Ω—ã –ø–æ —É–±—ã–≤–∞–Ω–∏—é –≤—Ä–µ–º–µ–Ω–∏
    for zid in zone_tags_data:
        zone_tags_data[zid] = sorted(zone_tags_data[zid], key=lambda x: x['minutes'], reverse=True)

    fig = go.Figure()
    for (tag, z), g in df.groupby(['ble_tag','zone_id']):
        tag_int = int(tag) if pd.notna(tag) else 0
        tag_name = "–í–Ω–µ –∑–æ–Ω—ã BLE-–º–∞—è—á–∫–æ–≤" if tag_int == 0 else f"–ú–µ—Ç–∫–∞ #{tag_int}"
        desc = tag_desc_map.get(str(tag_int), "").strip()
        title = f"{tag_name} ‚Äî {desc}" if desc else tag_name
        color = color_for_tag_zone(tag_int, z)
        tot = int(round_051(total_by_tag.get((tag, z), 0)))
        hovers = []
        for _, r in g.iterrows():
            hovers.append("<br>".join([
                f"{r['employee']}",
                f"–£—á–∞—Å—Ç–æ–∫: {r.get('area','')}" if pd.notna(r.get('area')) and str(r.get('area')).strip() else "",
                title,
                f"–ó–æ–Ω–∞: {r['zone_name']}",
                f"–í—Å–µ–≥–æ –≤ —ç—Ç–æ–π –º–µ—Ç–∫–µ (6‚Äì23): {tot} –º–∏–Ω",
                f"–ù–∞—á–∞–ª–æ: {r['start'].strftime('%d.%m %H:%M')}",
                f"–ö–æ–Ω–µ—Ü: {r['end'].strftime('%d.%m %H:%M')}",
                "–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: 1 –º–∏–Ω"
            ]))
        fig.add_trace(go.Bar(
            y=[user]*len(g), x=g['duration_ms'], base=g['start'], orientation='h',
            marker=dict(color=color, line=dict(color='rgba(0,0,0,0.15)', width=0.6)),
            hovertemplate='%{customdata}<extra></extra>', customdata=hovers, showlegend=False
        ))

    date_str = format_file_date_for_title(display_date)
    area_label = df['area'].iloc[0] if str(df['area'].iloc[0]).strip() else '–ë–µ–∑ —É—á–∞—Å—Ç–∫–∞'
    fig.update_layout(
        title=dict(text=f"{user} ‚Äî {date_str}", x=0.5, font=dict(size=20, color='#333')),
        width=980, height=max(360, row_height + 230),
        plot_bgcolor='white',
        paper_bgcolor='rgba(0,0,0,0)',
        margin=dict(l=110, r=20, t=70, b=80),
        barmode='overlay', hoverlabel=dict(font=dict(size=10))
    )
    fig.update_xaxes(
        title=dict(text="–í—Ä–µ–º—è (6:00‚Äì23:00)", font=dict(size=16, color="#333")),
        type='date', tickformat="%H:%M", dtick=3600000,
        range=[ws, we], showgrid=True, gridcolor="#e0e0e0", gridwidth=1,
        linecolor="#333", linewidth=2
    )
    fig.update_yaxes(
        title=dict(text="–°–æ—Ç—Ä—É–¥–Ω–∏–∫", font=dict(size=16, color="#333")),
        tickfont=dict(size=13, color="#333"), categoryorder="array", categoryarray=[user],
        showgrid=True, gridcolor="#e0e0e0", gridwidth=1, linecolor="#333", linewidth=2
    )

    # –ü–∞–Ω–µ–ª—å —Å–ø—Ä–∞–≤–∞: –≤—Ä–µ–º—è –ø–æ –∑–æ–Ω–∞–º (6‚Äì23) —Å accordion –¥–ª—è –º–µ—Ç–æ–∫
    zone_names = {0:"–í–Ω–µ –∑–æ–Ω—ã BLE-–º–∞—è—á–∫–æ–≤",1:"–ó–æ–Ω—ã –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è —Ä–∞–±–æ—Ç",2:"–°—Ç–æ–ª–æ–≤—ã–µ",3:"–û–ø–∞—Å–Ω—ã–µ –∑–æ–Ω—ã",4:"–ö—É—Ä–∏–ª–∫–∏",5:"–ó–æ–Ω—ã –æ—Ç–¥—ã—Ö–∞",6:"–í–ñ–ì",7:"–¢—É–∞–ª–µ—Ç—ã",8:"–û—Å—Ç–∞–Ω–æ–≤–∫–∏ –∞–≤—Ç–æ–±—É—Å–æ–≤",9:"–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–µ –ø–æ–º–µ—â–µ–Ω–∏—è",10:"–ó–æ–Ω–∞ –≤—ã–¥–∞—á–∏ WW",11:"–°–∫–ª–∞–¥",12:"–ú–∞—Å—Ç–µ—Ä—Å–∫–∏–µ",13:"–ö–ü–ü"}
    order = [1,4,10,13,2,7,0] + [z for z in zone_sum.index if z not in [1,4,10,13,2,7,0]]
    
    # –û–±—â–µ–µ –≤—Ä–µ–º—è –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ (—Å—É–º–º–∞ –≤—Å–µ—Ö –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–∏–Ω—É—Ç)
    total_presence = int(zone_sum.sum())
    
    items = []
    for zid in order:
        if zid not in zone_sum.index: continue
        mins = int(zone_sum.loc[zid])
        pct = round(mins / total_presence * 100, 1) if total_presence > 0 else 0
        name = zone_names.get(zid, f"–ó–æ–Ω–∞ {zid}")
        color = PALETTES.get(zid, PALETTES['other'])[0]
        light_color = lighten_color(color, 0.4)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –º–µ—Ç–æ–∫ –¥–ª—è —ç—Ç–æ–π –∑–æ–Ω—ã
        tags_in_zone = zone_tags_data.get(zid, [])
        tags_html = ""
        if tags_in_zone:
            tag_items = []
            for t in tags_in_zone:
                tag_int = t['tag']
                tag_mins = t['minutes']
                tag_pct = round(tag_mins / total_presence * 100, 1) if total_presence > 0 else 0
                tag_name = "–í–Ω–µ –∑–æ–Ω—ã" if tag_int == 0 else f"#{tag_int}"
                desc = tag_desc_map.get(str(tag_int), "").strip()
                tag_label = f"{tag_name} ({desc})" if desc else tag_name
                tag_items.append(f"<div class='tag-row' style='background:{light_color}'><span class='tag-name'>{tag_label}</span><span class='tag-val'>{tag_mins} –º–∏–Ω ({tag_pct}%)</span></div>")
            tags_html = "".join(tag_items)
        
        items.append(f"""
        <div class='zone-accordion'>
          <div class='zone-header' onclick='toggleZone(this)'>
            <span class='zone-toggle'>‚ñ∂</span>
            <span class='dot' style='background:{color}'></span>
            <span class='zname'>{name}</span>
            <span class='zval'>{mins} –º–∏–Ω ({pct}%)</span>
          </div>
          <div class='zone-content' style='display:none;'>
            {tags_html if tags_html else "<div class='tag-empty'>–ù–µ—Ç –º–µ—Ç–æ–∫</div>"}
          </div>
        </div>""")
    
    panel_html = f"""
    <div class="zone-card">
      <div class="zone-title">–í—Ä–µ–º—è –ø–æ –∑–æ–Ω–∞–º (6:00‚Äì23:00)</div>
      {''.join(items) if items else "<div class='zone-empty'>–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö</div>"}
    </div>
    """
    return fig, panel_html

def export_chart_auto(fig, date_str, area_suffix=None, employee=None):
    if not fig: return
    area_label = str(area_suffix).strip() if area_suffix else "–û–±—â–∞—è"
    user_label = f" ‚Äî {employee}" if employee else ""
    safe_date = str(date_str).replace('/','-')
    filename = f"AA_BLE –¢–∞–π–º–ª–∞–π–Ω {area_label} {safe_date}{user_label}.html"
    try:
        page_title = f"AA_BLE –¢–∞–π–º–ª–∞–π–Ω ‚Äî {area_label} ‚Äî {date_str}{user_label}"
        html_string = fig.to_html(include_plotlyjs='cdn', config={
            'displayModeBar': True, 'displaylogo': False,
            'toImageButtonOptions': {'format':'png','filename':filename.replace('.html',''),
                                     'height': int(fig.layout.height or 800),
                                     'width': int(fig.layout.width or 980), 'scale': 2},
            'responsive': True
        })
        custom_html = html_string.replace('<head>', f'''<head>
<meta charset="utf-8"><title>{page_title}</title>
<style>body{{font-family:Arial;margin:0;padding:20px;background:#f8f9fa;}}
.plotly-graph-div{{background:#fff;border-radius:8px;box-shadow:0 2px 10px rgba(0,0,0,0.1);padding:20px;}}</style>''')
        with open(filename,'w',encoding='utf-8') as f: f.write(custom_html)
        files.download(filename)
        print(f"‚úÖ HTML '{filename}' —Å–∫–∞—á–∞–Ω")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {e}")

def fig_to_div(fig, title_text):
    return fig.to_html(include_plotlyjs=False, full_html=False, config={
        'displayModeBar': True, 'displaylogo': False,
        'toImageButtonOptions': {'format':'png','filename':title_text.replace(' ','_'),
                                 'height': int(fig.layout.height or 800),
                                 'width': int(fig.layout.width or 980), 'scale': 2},
        'responsive': True
    })

def export_combined_html(sections, filename, page_title):
    toc_items, content = [], []
    for i, sec in enumerate(sections, 1):
        anchor = f"sec{i}"
        h = sec.get('heading') or ''
        sh = sec.get('subheading') or ''
        toc_items.append(f'<li><a href="#{anchor}">{h}{" ‚Äî " + sh if sh else ""}</a></li>')
        content.append(f'''
<section id="{anchor}">
  <div class="back"><a href="#toc">‚Üê –ö –æ–≥–ª–∞–≤–ª–µ–Ω–∏—é</a></div>
  <h2>{h}{(" ‚Äî " + sh) if sh else ""}</h2>
  <div class="row">
    <div class="panel">{sec['panel_html']}</div>
    <div class="plot">{sec['fig_div']}</div>
  </div>
  <hr/>
</section>
''')
    html = f'''<!DOCTYPE html>
<html lang="ru">
<head>
<meta charset="utf-8"/>
<title>{page_title}</title>
<script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
<style>
 body {{ font-family: Arial, sans-serif; background:#f8f9fa; margin:0; padding:0; }}
 .container {{ max-width: 1320px; margin: 0 auto; padding: 24px; }}
 .card {{ background:#fff; border-radius:8px; box-shadow:0 2px 10px rgba(0,0,0,0.1); padding:20px; }}
 h1 {{ margin:0 0 16px; color:#333; }}
 h2 {{ margin:12px 0; color:#333; }}
 ul.toc > li {{ margin:6px 0; }}
 a {{ color:#0d6efd; text-decoration:none; }} a:hover {{ text-decoration:underline; }}
 .row {{ display:flex; gap:16px; align-items:flex-start; }}
 .panel {{ width:300px; flex:0 0 300px; }}
 .plot {{ flex:1; min-width:0; }}
 .zone-card {{ background:#fff; border-radius:8px; box-shadow:0 2px 10px rgba(0,0,0,0.1); padding:14px; }}
 .zone-title {{ font-weight:bold; margin:4px 0 10px; }}
 .zone-accordion {{ margin-bottom:2px; }}
 .zone-header {{ display:flex; align-items:center; padding:8px 6px; cursor:pointer; border-radius:4px; transition:background 0.2s; }}
 .zone-header:hover {{ background:#f0f0f0; }}
 .zone-toggle {{ font-size:10px; margin-right:6px; color:#666; transition:transform 0.2s; }}
 .zone-toggle.open {{ transform:rotate(90deg); }}
 .dot {{ display:inline-block; width:12px; height:12px; border-radius:50%; margin-right:8px; flex-shrink:0; }}
 .zname {{ flex:1; font-size:13px; }}
 .zval {{ margin-left:12px; font-weight:bold; color:#333; font-size:13px; }}
 .zone-content {{ margin-left:28px; padding-left:8px; border-left:2px solid #e0e0e0; }}
 .tag-row {{ display:flex; align-items:center; justify-content:space-between; padding:5px 8px; margin:2px 0; border-radius:4px; font-size:12px; }}
 .tag-name {{ flex:1; color:#444; }}
 .tag-val {{ margin-left:8px; font-weight:600; color:#333; }}
 .tag-empty {{ font-size:11px; color:#999; padding:4px 8px; }}
 .zone-empty {{ font-size:12px; color:#999; padding:8px; }}
 .back {{ margin: 8px 0 4px }}
 hr {{ margin: 24px 0; border:0; border-top:1px solid #ddd }}
</style>
</head>
<body>
<div class="container">
  <div class="card" id="toc">
    <h1>{page_title}</h1>
    <h3 style="margin-top:0">–û–≥–ª–∞–≤–ª–µ–Ω–∏–µ</h3>
    <ul class="toc">{''.join(toc_items)}</ul>
  </div>
  <div style="height:16px"></div>
  {''.join(content)}
</div>
<script>
function toggleZone(header) {{
  var content = header.nextElementSibling;
  var toggle = header.querySelector('.zone-toggle');
  if (content.style.display === 'none') {{
    content.style.display = 'block';
    toggle.classList.add('open');
  }} else {{
    content.style.display = 'none';
    toggle.classList.remove('open');
  }}
}}
</script>
</body>
</html>'''
    with open(filename, 'w', encoding='utf-8') as f: f.write(html)
    files.download(filename)
    print(f"‚úÖ –û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π HTML '{filename}' —Å–∫–∞—á–∞–Ω.")

def export_overall_excel_period(overall_by_date: dict):
    if not overall_by_date:
        print("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Excel"); return
    dates_sorted = sorted(overall_by_date.keys())
    min_d = pd.to_datetime(min(dates_sorted)).strftime('%d.%m.%Y')
    max_d = pd.to_datetime(max(dates_sorted)).strftime('%d.%m.%Y')
    filename = f"AA_BLE –¢–∞–π–º–ª–∞–π–Ω—ã 6-23 {min_d.replace('.','-')}‚Äî{max_d.replace('.','-')}.xlsx"
    from openpyxl.utils import get_column_letter
    from openpyxl.styles import Alignment, Border, Side
    thin = Side(style='thin', color='FFAAAAAA')
    with pd.ExcelWriter(filename, engine='openpyxl') as w:
        for the_date in dates_sorted:
            df_x = overall_by_date[the_date].copy()
            if df_x is None or df_x.empty: continue
            events = df_x[['employee','area','ble_tag','zone_name','start','end','duration_minutes','tn_number']].rename(columns={
                'employee':'–°–æ—Ç—Ä—É–¥–Ω–∏–∫','area':'–£—á–∞—Å—Ç–æ–∫','ble_tag':'–ú–µ—Ç–∫–∞',
                'zone_name':'–ó–æ–Ω–∞','start':'–ù–∞—á–∞–ª–æ','end':'–ö–æ–Ω–µ—Ü',
                'duration_minutes':'–ú–∏–Ω—É—Ç—ã','tn_number':'–¢–ù'
            }).sort_values(['–°–æ—Ç—Ä—É–¥–Ω–∏–∫','–ù–∞—á–∞–ª–æ'])
            zone_pivot = df_x.pivot_table(index='employee', columns='zone_name', values='duration_minutes', aggfunc='sum', fill_value=0.0)
            zone_pivot = zone_pivot.applymap(round_051).reset_index().rename(columns={'employee':'–°–æ—Ç—Ä—É–¥–Ω–∏–∫'})
            tag = pd.to_datetime(the_date).strftime('%d.%m')
            sh_e = f"{tag} ‚Äî –¢–∞–±–ª–∏—Ü–∞ 6-23"; sh_z = f"{tag} ‚Äî –ó–æ–Ω—ã 6-23"
            events.to_excel(w, index=False, sheet_name=sh_e)
            zone_pivot.to_excel(w, index=False, sheet_name=sh_z)
            for ws in (w.sheets[sh_e], w.sheets[sh_z]):
                ws.freeze_panes = 'A2'
                max_row = ws.max_row; max_col = ws.max_column
                for c in range(1, max_col + 1):
                    ws.column_dimensions[get_column_letter(c)].width = 20
                for r in range(1, max_row + 1):
                    for c in range(1, max_col + 1):
                        cell = ws.cell(row=r, column=c)
                        cell.alignment = Alignment(wrap_text=True, vertical='top')
                        cell.border = Border(left=thin, right=thin, top=thin, bottom=thin)
    files.download(filename)
    print(f"‚úÖ Excel '{filename}' —Å–∫–∞—á–∞–Ω.")

def create_aable_presence_analysis():
    print("=" * 80)
    print("üè¢ –¢–ê–ô–ú–õ–ê–ô–ù–´ AA_BLE (6:00‚Äì23:00, –ø–æ–º–∏–Ω—É—Ç–Ω–æ; —Å–ø—Ä–∞–≤–∞ ‚Äî –æ–∫–Ω–æ ¬´–í—Ä–µ–º—è –ø–æ –∑–æ–Ω–∞–º¬ª)")
    print("=" * 80)
    try:
        row_height = int(input("–í—ã—Å–æ—Ç–∞ —Å—Ç—Ä–æ–∫–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ (–ø–∏–∫—Å), Enter=60: ").strip() or "60")
    except: row_height = 60
    print("\nüìà –®–ê–ì 1: –ó–∞–≥—Ä—É–∑–∫–∞ aa_ble‚Ä¶")
    per_ans = input("–ü–µ—Ä–∏–æ–¥ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 10.09.2025-14.09.2025, Enter ‚Äî –≤—Å–µ): ").strip()
    date_from = date_to = None
    if per_ans:
        m = re.findall(r'(\d{1,2}[./-]\d{1,2}[./-]\d{2,4})', per_ans)
        if len(m) >= 2: date_from, date_to = m[0], m[1]
    aable = load_aable_second_sheet_multi(date_from=date_from, date_to=date_to)
    if aable is None or aable.empty:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö aa_ble"); return
    print("\nüìç –®–ê–ì 2: –ñ—É—Ä–Ω–∞–ª BLE (–Ω–∞–∑–≤–∞–Ω–∏—è –º–µ—Ç–æ–∫)‚Ä¶")
    tag_desc_map = attach_ble_desc_map(load_ble_journal())
    print("\nüóÇ –®–ê–ì 3: '–ü—Ä–∏–≤—è–∑–∫–∞ –ª—é–¥–µ–π'‚Ä¶")
    people_mapping_df = load_people_mapping()
    if people_mapping_df is None:
        print("‚ùå –ù–µ–ª—å–∑—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –±–µ–∑ '–ü—Ä–∏–≤—è–∑–∫–∞ –ª—é–¥–µ–π'"); return
    area_map = build_area_map(people_mapping_df)
    fio_map = build_fio_map(people_mapping_df)
    aable['ble_tag'] = pd.to_numeric(aable['ble_tag'], errors='coerce')
    aable['zone_id'] = pd.to_numeric(aable['zone_id'], errors='coerce').fillna(0).astype(int)
    print("\nüß≠ –ü—Ä–æ–≤–µ—Ä–∫–∞ '–º–µ—Ç–∫–∞ 0'‚Ä¶"); _ = report_zero_metka(aable)
    print("\nüîç –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑—Ä—ã–≤–æ–≤ –≤–æ –≤—Ä–µ–º–µ–Ω–∏‚Ä¶"); log_time_gaps(aable, fio_map)
    print("\nüîç –ê–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–∫ –ø–æ –∑–æ–Ω–∞–º‚Ä¶"); _ = analyze_tag_zones(aable)
    print("\nüîç –®–ê–ì 4: –ü–æ–º–∏–Ω—É—Ç–Ω—ã–µ –æ—Ç—Ä–µ–∑–∫–∏ –ø–æ –º–µ—Ç–∫–∞–º‚Ä¶")
    segments = build_segments_all(aable, area_map, fio_map)
    if segments.empty:
        print("‚ùå –ù–µ—Ç —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è"); return
    segments['area_key'] = segments['area'].fillna('').astype(str).str.strip().str.lower().str.replace(' ','', regex=False)
    all_dates = sorted(segments['date'].dropna().unique())
    clear_saved_charts()

    def filter_by_area(source_df, area_key):
        if area_key is None: return source_df.copy()
        return source_df[source_df['area_key'] == area_key].copy()

    combined_sections = []; overall_by_date = {}
    for the_date in all_dates:
        df_day = segments[segments['date'] == the_date].copy()
        if df_day.empty: continue
        file_date_mode = df_day['file_date'].dropna().astype(str)
        display_date = pd.to_datetime(file_date_mode.mode().iloc[0]).date() if not file_date_mode.empty else pd.to_datetime(the_date).date()
        date_str = format_file_date_for_title(display_date)
        print(f"\nüé® –î–∞—Ç–∞ (–∏–∑ —Ñ–∞–π–ª–∞): {date_str}")
        ws = datetime.combine(display_date, dtime(6,0))
        we = datetime.combine(display_date, dtime(23,0))
        df_day_8_22 = df_day[(pd.to_datetime(df_day['start']) >= ws) & (pd.to_datetime(df_day['start']) < we)].copy()

        areas_today = (df_day['area_key'].fillna('').astype(str).str.strip().unique().tolist())
        for ak in areas_today:
            df_area = filter_by_area(df_day, ak if ak else '')
            area_label = df_area['area'].dropna().astype(str).str.strip().unique()
            area_label = area_label[0] if len(area_label)>0 else "–ë–µ–∑ —É—á–∞—Å—Ç–∫–∞"
            if df_area.empty: continue
            for emp, g in df_area.groupby('employee'):
                fig, panel_html = create_user_timeline_chart_window(g, tag_desc_map=tag_desc_map, row_height=row_height)
                if not fig: continue
                fig.update_layout(title_text=f"{emp} ‚Äî {date_str}")
                fig_div = fig_to_div(fig, fig.layout.title.text)
                combined_sections.append({'heading': f"{date_str}", 'subheading': f"{emp}",
                                          'panel_html': panel_html, 'fig_div': fig_div})
                LAST_EXPORTS.append({'fig': fig, 'date_str': date_str, 'area_suffix': area_label, 'employee': emp})
        overall_by_date[the_date] = df_day_8_22.copy()

    if all_dates:
        if len(all_dates)==1:
            page_title = f"AA_BLE –¢–∞–π–º–ª–∞–π–Ω—ã (6‚Äì23) ‚Äî {date_str}"
            filename = f"AA_BLE –¢–∞–π–º–ª–∞–π–Ω—ã 6-23 {date_str}.html"
        else:
            min_d = format_file_date_for_title(pd.to_datetime(min(all_dates)).date())
            max_d = format_file_date_for_title(pd.to_datetime(max(all_dates)).date())
            page_title = f"AA_BLE –¢–∞–π–º–ª–∞–π–Ω—ã (6‚Äì23) ‚Äî –ø–µ—Ä–∏–æ–¥ {min_d}‚Äì{max_d}"
            filename = f"AA_BLE –¢–∞–π–º–ª–∞–π–Ω—ã 6-23 {min_d}‚Äî{max_d}.html"
        export_combined_html(combined_sections, filename, page_title)

    export_overall_excel_period(overall_by_date)
    print("\n‚úÖ –ì–û–¢–û–í–û! –û–∫–Ω–æ 6:00‚Äì23:00, –ø–æ–º–∏–Ω—É—Ç–Ω—ã–π —É—á—ë—Ç; —Å–ø—Ä–∞–≤–∞ ‚Äî –æ—Ç–¥–µ–ª—å–Ω–æ–µ –æ–∫–Ω–æ —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º –ø–æ –ó–û–ù–ê–ú; –Ω–∞ –¥–∏–∞–≥—Ä–∞–º–º–µ –º–µ—Ç–∫–∏, –æ–∫—Ä–∞—à–µ–Ω–Ω—ã–µ –≤ –æ—Ç—Ç–µ–Ω–∫–∏ —Å–≤–æ–µ–π –∑–æ–Ω—ã.")
    print("–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –≤—ã–≥—Ä—É–∑–∫–∞ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤: redownload_last_charts().")

print("=" * 100)
print("üè¢ AA_BLE –¢–ê–ô–ú–õ–ê–ô–ù–´ (6:00‚Äì23:00, –ø–æ–º–∏–Ω—É—Ç–Ω–æ; —Å–ø—Ä–∞–≤–∞ ‚Äî –æ–∫–Ω–æ ¬´–í—Ä–µ–º—è –ø–æ –∑–æ–Ω–∞–º¬ª)")
print("=" * 100)
print("üß≠ –ó–æ–Ω—ã: 1 –∑–µ–ª—ë–Ω—ã–µ (–ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è —Ä–∞–±–æ—Ç), 4 –∫—Ä–∞—Å–Ω—ã–µ (–∫—É—Ä–∏–ª–∫–∏), 10 —Å–∏–Ω–∏–µ (–≤—ã–¥–∞—á–∞ WW), 13 –æ—Ä–∞–Ω–∂–µ–≤—ã–µ (–ö–ü–ü), 0 —Å–µ—Ä—ã–µ, –ø—Ä–æ—á–µ–µ ‚Äî —Å–µ—Ä—ã–µ.")
print("üìÖ –î–∞—Ç–∞ –≤ –æ—Ç—á—ë—Ç–µ –±–µ—Ä—ë—Ç—Å—è –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ (YYYY-MM-DD –∏ –¥—Ä. —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ ‚Üí DD-MM-YYYY).")
print("üöÄ –ó–∞–ø—É—Å–∫: create_aable_presence_analysis()")
print("=" * 100)
print()
print("‚úÖ –ì–û–¢–û–í–û! –ó–∞–ø—É—Å—Ç–∏—Ç–µ create_aable_presence_analysis() –¥–ª—è –Ω–∞—á–∞–ª–∞.")
